{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/lish-moa/train_features.csv\n/kaggle/input/lish-moa/test_features.csv\n/kaggle/input/lish-moa/train_targets_nonscored.csv\n/kaggle/input/lish-moa/sample_submission.csv\n/kaggle/input/lish-moa/train_targets_scored.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Read Input Files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(os.path.join('/kaggle/input/lish-moa', 'train_features.csv'))\ntest_data = pd.read_csv(os.path.join('/kaggle/input/lish-moa' , 'test_features.csv'))\n\ntrain_target = pd.read_csv(os.path.join('/kaggle/input/lish-moa','train_targets_scored.csv'))","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Print Shape of Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"train_data.shap: {}  , train_target.shap: {}  , test_data.shap: {} \".format(train_data.shape , train_target.shape , test_data.shape))","execution_count":164,"outputs":[{"output_type":"stream","text":"train_data.shap: (23814, 876)  , train_target.shap: (23814, 207)  , test_data.shap: (3982, 876) \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"NGTypeFeature = sum(train_data.columns.to_series().str.contains('g-') == True )\nNCTypeFeature = sum(train_data.columns.to_series().str.contains('c-') == True )\n\nprint(\"NGTypeFeature = {} \\nNCTypeFeature = {}\".format(NGTypeFeature , NCTypeFeature))","execution_count":165,"outputs":[{"output_type":"stream","text":"NGTypeFeature = 772 \nNCTypeFeature = 100\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Define a Neural Network To Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn.functional as F\nimport torch.nn as nn\n\nclass MultiLabelClassifer(nn.Module):\n    #TO-DO: Documentation\n    def __init__(self , input_feature , hidden_dim , output_dim):\n        super(MultiLabelClassifer , self).__init__()\n        \n        self.fc1 = nn.Linear(in_features = input_feature , out_features = 2000)\n        #TO-DO: As close features are related here, convoluation layer will help here\n        #TO-DO: Later add and play with Convolutatin layer, to see accurracy difference\n        self.fc2 = nn.Linear( in_features = 2000 , out_features  = 4000)\n        self.fc3 = nn.Linear( in_features = 4000 , out_features  = 1000)\n        self.fc4 = nn.Linear(in_features = 1000 , out_features = 400)\n        self.fc5 = nn.Linear(in_features = 400 , out_features = output_dim)\n        self.drop = nn.Dropout(0.4) # dropout with 30% prob\n        \n        self.sig = nn.Sigmoid()\n        #TO-DO: Define output layer so that it be as per Question requirement\n    def forward(self, x):\n        \n        # (1) input layer\n        \n        t = x\n        \n        \n        # (2) Hidden Linear Layer\n        \n        t = self.fc1(t)\n        t = F.relu(t)\n        #3\n        \n        t = self.fc2(t)\n        t = F.relu(t)\n        #4\n        \n        t= self.fc3(t)\n        t = F.relu(t)\n        t = self.drop(t)\n        \n        #5\n        \n        t = self.fc4(t)\n        t = F.relu(t)\n        #6\n        \n        t = self.drop(t)\n        \n        t = self.fc5(t)\n        t = F.relu(t)\n        \n        # (7) Output Layer\n        \n        t = self.sig(t)\n        \n        return t\n        ","execution_count":166,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"train_rf = train_data.copy()\ntrain_data.head()\n\ntest_rf = test_data.copy()\ntrain_rf.head()","execution_count":274,"outputs":[{"output_type":"execute_result","execution_count":274,"data":{"text/plain":"         sig_id cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3  \\\n0  id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208   \n1  id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604   \n2  id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764   \n3  id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288   \n4  id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919   \n\n      g-4     g-5  ...    c-90    c-91    c-92    c-93    c-94    c-95  \\\n0 -0.1944 -1.0120  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584   \n1  1.0190  0.5207  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899   \n2 -0.0323  1.2390  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174   \n3  4.0620 -0.8095  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880   \n4  1.4180 -0.8244  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031   \n\n     c-96    c-97    c-98    c-99  \n0 -0.3981  0.2139  0.3801  0.4176  \n1  0.1522  0.1241  0.6077  0.7371  \n2 -0.6417 -0.2187 -1.4080  0.6931  \n3 -1.6210 -0.8784 -0.3876 -0.8154  \n4  0.1094  0.2885 -0.3786  0.7125  \n\n[5 rows x 876 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sig_id</th>\n      <th>cp_type</th>\n      <th>cp_time</th>\n      <th>cp_dose</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>g-3</th>\n      <th>g-4</th>\n      <th>g-5</th>\n      <th>...</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_000644bb2</td>\n      <td>trt_cp</td>\n      <td>24</td>\n      <td>D1</td>\n      <td>1.0620</td>\n      <td>0.5577</td>\n      <td>-0.2479</td>\n      <td>-0.6208</td>\n      <td>-0.1944</td>\n      <td>-1.0120</td>\n      <td>...</td>\n      <td>0.2862</td>\n      <td>0.2584</td>\n      <td>0.8076</td>\n      <td>0.5523</td>\n      <td>-0.1912</td>\n      <td>0.6584</td>\n      <td>-0.3981</td>\n      <td>0.2139</td>\n      <td>0.3801</td>\n      <td>0.4176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_000779bfc</td>\n      <td>trt_cp</td>\n      <td>72</td>\n      <td>D1</td>\n      <td>0.0743</td>\n      <td>0.4087</td>\n      <td>0.2991</td>\n      <td>0.0604</td>\n      <td>1.0190</td>\n      <td>0.5207</td>\n      <td>...</td>\n      <td>-0.4265</td>\n      <td>0.7543</td>\n      <td>0.4708</td>\n      <td>0.0230</td>\n      <td>0.2957</td>\n      <td>0.4899</td>\n      <td>0.1522</td>\n      <td>0.1241</td>\n      <td>0.6077</td>\n      <td>0.7371</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_000a6266a</td>\n      <td>trt_cp</td>\n      <td>48</td>\n      <td>D1</td>\n      <td>0.6280</td>\n      <td>0.5817</td>\n      <td>1.5540</td>\n      <td>-0.0764</td>\n      <td>-0.0323</td>\n      <td>1.2390</td>\n      <td>...</td>\n      <td>-0.7250</td>\n      <td>-0.6297</td>\n      <td>0.6103</td>\n      <td>0.0223</td>\n      <td>-1.3240</td>\n      <td>-0.3174</td>\n      <td>-0.6417</td>\n      <td>-0.2187</td>\n      <td>-1.4080</td>\n      <td>0.6931</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_0015fd391</td>\n      <td>trt_cp</td>\n      <td>48</td>\n      <td>D1</td>\n      <td>-0.5138</td>\n      <td>-0.2491</td>\n      <td>-0.2656</td>\n      <td>0.5288</td>\n      <td>4.0620</td>\n      <td>-0.8095</td>\n      <td>...</td>\n      <td>-2.0990</td>\n      <td>-0.6441</td>\n      <td>-5.6300</td>\n      <td>-1.3780</td>\n      <td>-0.8632</td>\n      <td>-1.2880</td>\n      <td>-1.6210</td>\n      <td>-0.8784</td>\n      <td>-0.3876</td>\n      <td>-0.8154</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_001626bd3</td>\n      <td>trt_cp</td>\n      <td>72</td>\n      <td>D2</td>\n      <td>-0.3254</td>\n      <td>-0.4009</td>\n      <td>0.9700</td>\n      <td>0.6919</td>\n      <td>1.4180</td>\n      <td>-0.8244</td>\n      <td>...</td>\n      <td>0.0042</td>\n      <td>0.0048</td>\n      <td>0.6670</td>\n      <td>1.0690</td>\n      <td>0.5523</td>\n      <td>-0.3031</td>\n      <td>0.1094</td>\n      <td>0.2885</td>\n      <td>-0.3786</td>\n      <td>0.7125</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 876 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## One hot coding of input feature and Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.utils.data\nimport torch\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder,Normalizer\n\nignore_columns = ['sig_id','cp_type']\n\ntrain_columns = [x for x in train_data.columns if x not in ignore_columns]\nprint(len(train_columns))\ntrain = train_rf[train_columns]\nidx = train.index\ncol = train.columns\nprint(\"size of train is {}\",train.shape)\ntrain.head()\n\n\n\n","execution_count":292,"outputs":[{"output_type":"stream","text":"874\nsize of train is {} (23814, 874)\n","name":"stdout"},{"output_type":"execute_result","execution_count":292,"data":{"text/plain":"   cp_time cp_dose     g-0     g-1     g-2     g-3     g-4     g-5     g-6  \\\n0       24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220   \n1       72      D1  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341   \n2       48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715   \n3       48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590   \n4       72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800   \n\n      g-7  ...    c-90    c-91    c-92    c-93    c-94    c-95    c-96  \\\n0 -0.0326  ...  0.2862  0.2584  0.8076  0.5523 -0.1912  0.6584 -0.3981   \n1  0.3372  ... -0.4265  0.7543  0.4708  0.0230  0.2957  0.4899  0.1522   \n2  0.2155  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240 -0.3174 -0.6417   \n3  0.1792  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632 -1.2880 -1.6210   \n4 -0.1498  ...  0.0042  0.0048  0.6670  1.0690  0.5523 -0.3031  0.1094   \n\n     c-97    c-98    c-99  \n0  0.2139  0.3801  0.4176  \n1  0.1241  0.6077  0.7371  \n2 -0.2187 -1.4080  0.6931  \n3 -0.8784 -0.3876 -0.8154  \n4  0.2885 -0.3786  0.7125  \n\n[5 rows x 874 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cp_time</th>\n      <th>cp_dose</th>\n      <th>g-0</th>\n      <th>g-1</th>\n      <th>g-2</th>\n      <th>g-3</th>\n      <th>g-4</th>\n      <th>g-5</th>\n      <th>g-6</th>\n      <th>g-7</th>\n      <th>...</th>\n      <th>c-90</th>\n      <th>c-91</th>\n      <th>c-92</th>\n      <th>c-93</th>\n      <th>c-94</th>\n      <th>c-95</th>\n      <th>c-96</th>\n      <th>c-97</th>\n      <th>c-98</th>\n      <th>c-99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24</td>\n      <td>D1</td>\n      <td>1.0620</td>\n      <td>0.5577</td>\n      <td>-0.2479</td>\n      <td>-0.6208</td>\n      <td>-0.1944</td>\n      <td>-1.0120</td>\n      <td>-1.0220</td>\n      <td>-0.0326</td>\n      <td>...</td>\n      <td>0.2862</td>\n      <td>0.2584</td>\n      <td>0.8076</td>\n      <td>0.5523</td>\n      <td>-0.1912</td>\n      <td>0.6584</td>\n      <td>-0.3981</td>\n      <td>0.2139</td>\n      <td>0.3801</td>\n      <td>0.4176</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72</td>\n      <td>D1</td>\n      <td>0.0743</td>\n      <td>0.4087</td>\n      <td>0.2991</td>\n      <td>0.0604</td>\n      <td>1.0190</td>\n      <td>0.5207</td>\n      <td>0.2341</td>\n      <td>0.3372</td>\n      <td>...</td>\n      <td>-0.4265</td>\n      <td>0.7543</td>\n      <td>0.4708</td>\n      <td>0.0230</td>\n      <td>0.2957</td>\n      <td>0.4899</td>\n      <td>0.1522</td>\n      <td>0.1241</td>\n      <td>0.6077</td>\n      <td>0.7371</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>48</td>\n      <td>D1</td>\n      <td>0.6280</td>\n      <td>0.5817</td>\n      <td>1.5540</td>\n      <td>-0.0764</td>\n      <td>-0.0323</td>\n      <td>1.2390</td>\n      <td>0.1715</td>\n      <td>0.2155</td>\n      <td>...</td>\n      <td>-0.7250</td>\n      <td>-0.6297</td>\n      <td>0.6103</td>\n      <td>0.0223</td>\n      <td>-1.3240</td>\n      <td>-0.3174</td>\n      <td>-0.6417</td>\n      <td>-0.2187</td>\n      <td>-1.4080</td>\n      <td>0.6931</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48</td>\n      <td>D1</td>\n      <td>-0.5138</td>\n      <td>-0.2491</td>\n      <td>-0.2656</td>\n      <td>0.5288</td>\n      <td>4.0620</td>\n      <td>-0.8095</td>\n      <td>-1.9590</td>\n      <td>0.1792</td>\n      <td>...</td>\n      <td>-2.0990</td>\n      <td>-0.6441</td>\n      <td>-5.6300</td>\n      <td>-1.3780</td>\n      <td>-0.8632</td>\n      <td>-1.2880</td>\n      <td>-1.6210</td>\n      <td>-0.8784</td>\n      <td>-0.3876</td>\n      <td>-0.8154</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>72</td>\n      <td>D2</td>\n      <td>-0.3254</td>\n      <td>-0.4009</td>\n      <td>0.9700</td>\n      <td>0.6919</td>\n      <td>1.4180</td>\n      <td>-0.8244</td>\n      <td>-0.2800</td>\n      <td>-0.1498</td>\n      <td>...</td>\n      <td>0.0042</td>\n      <td>0.0048</td>\n      <td>0.6670</td>\n      <td>1.0690</td>\n      <td>0.5523</td>\n      <td>-0.3031</td>\n      <td>0.1094</td>\n      <td>0.2885</td>\n      <td>-0.3786</td>\n      <td>0.7125</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 874 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test_rf[train_columns]\ntarget = train_target.iloc[:,1:].values\n#https://stackoverflow.com/questions/54160370/how-to-use-sklearn-column-transformer/54160620\ntransform = ColumnTransformer([('o',OneHotEncoder(),[0,1]),('s',Normalizer(),list(range(3,train.shape[1])))])\nprint(\"size before transform train.shape:{} test.shape{}\".format(train.shape,test.shape))\ntrain = transform.fit_transform(train)\ntest = transform.transform(test)\n\nprint(\"size AFTER transform train.shape:{} test.shape{}\".format(train.shape,test.shape))","execution_count":293,"outputs":[{"output_type":"stream","text":"size before transform train.shape:(23814, 874) test.shape(3982, 874)\nsize AFTER transform train.shape:(23814, 876) test.shape(3982, 876)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_rf['cp_dose'] = train_data['cp_dose'].replace({\"D1\":1 , \"D2\":2})\n#train_rf['cp_type'] = train_rf['cp_type'].replace({\"trt_cp\":1 , \"ctl_vehicle\":2})\n\n#test_rf['cp_dose'] = test_data['cp_dose'].replace({\"D1\":1 , \"D2\":2})\n#test_rf['cp_type'] = test_data['cp_type'].replace({\"trt_cp\":1 , \"ctl_vehicle\":2})\nprint(type(train))\nprint(len(col))\nprint(len(idx))\nprint(train.shape)\nprint(type(col))\n\n#col = pd.concat(['p1', 'p2'] ,col)\ntrain_df = pd.DataFrame(data = train,index = idx ) #Check if encoding is successful or not\n","execution_count":296,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n874\n23814\n(23814, 876)\n<class 'pandas.core.indexes.base.Index'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":297,"outputs":[{"output_type":"execute_result","execution_count":297,"data":{"text/plain":"   0    1    2    3    4         5         6         7         8         9    \\\n0  1.0  0.0  0.0  1.0  0.0  0.025030 -0.011126 -0.027862 -0.008725 -0.045420   \n1  0.0  0.0  1.0  1.0  0.0  0.018548  0.013574  0.002741  0.046245  0.023631   \n2  0.0  1.0  0.0  1.0  0.0  0.020432  0.054585 -0.002684 -0.001135  0.043520   \n3  0.0  1.0  0.0  1.0  0.0 -0.006312 -0.006730  0.013400  0.102930 -0.020513   \n4  0.0  0.0  1.0  0.0  1.0 -0.014177  0.034302  0.024468  0.050145 -0.029153   \n\n   ...       866       867       868       869       870       871       872  \\\n0  ...  0.012845  0.011597  0.036246  0.024788 -0.008581  0.029550 -0.017867   \n1  ... -0.019356  0.034232  0.021366  0.001044  0.013420  0.022233  0.006907   \n2  ... -0.025466 -0.022118  0.021437  0.000783 -0.046506 -0.011149 -0.022540   \n3  ... -0.053188 -0.016321 -0.142663 -0.034918 -0.021873 -0.032638 -0.041076   \n4  ...  0.000149  0.000170  0.023587  0.037803  0.019531 -0.010719  0.003869   \n\n        873       874       875  \n0  0.009600  0.017059  0.018742  \n1  0.005632  0.027579  0.033451  \n2 -0.007682 -0.049456  0.024345  \n3 -0.022259 -0.009822 -0.020662  \n4  0.010202 -0.013388  0.025196  \n\n[5 rows x 876 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>866</th>\n      <th>867</th>\n      <th>868</th>\n      <th>869</th>\n      <th>870</th>\n      <th>871</th>\n      <th>872</th>\n      <th>873</th>\n      <th>874</th>\n      <th>875</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.025030</td>\n      <td>-0.011126</td>\n      <td>-0.027862</td>\n      <td>-0.008725</td>\n      <td>-0.045420</td>\n      <td>...</td>\n      <td>0.012845</td>\n      <td>0.011597</td>\n      <td>0.036246</td>\n      <td>0.024788</td>\n      <td>-0.008581</td>\n      <td>0.029550</td>\n      <td>-0.017867</td>\n      <td>0.009600</td>\n      <td>0.017059</td>\n      <td>0.018742</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.018548</td>\n      <td>0.013574</td>\n      <td>0.002741</td>\n      <td>0.046245</td>\n      <td>0.023631</td>\n      <td>...</td>\n      <td>-0.019356</td>\n      <td>0.034232</td>\n      <td>0.021366</td>\n      <td>0.001044</td>\n      <td>0.013420</td>\n      <td>0.022233</td>\n      <td>0.006907</td>\n      <td>0.005632</td>\n      <td>0.027579</td>\n      <td>0.033451</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.020432</td>\n      <td>0.054585</td>\n      <td>-0.002684</td>\n      <td>-0.001135</td>\n      <td>0.043520</td>\n      <td>...</td>\n      <td>-0.025466</td>\n      <td>-0.022118</td>\n      <td>0.021437</td>\n      <td>0.000783</td>\n      <td>-0.046506</td>\n      <td>-0.011149</td>\n      <td>-0.022540</td>\n      <td>-0.007682</td>\n      <td>-0.049456</td>\n      <td>0.024345</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-0.006312</td>\n      <td>-0.006730</td>\n      <td>0.013400</td>\n      <td>0.102930</td>\n      <td>-0.020513</td>\n      <td>...</td>\n      <td>-0.053188</td>\n      <td>-0.016321</td>\n      <td>-0.142663</td>\n      <td>-0.034918</td>\n      <td>-0.021873</td>\n      <td>-0.032638</td>\n      <td>-0.041076</td>\n      <td>-0.022259</td>\n      <td>-0.009822</td>\n      <td>-0.020662</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.014177</td>\n      <td>0.034302</td>\n      <td>0.024468</td>\n      <td>0.050145</td>\n      <td>-0.029153</td>\n      <td>...</td>\n      <td>0.000149</td>\n      <td>0.000170</td>\n      <td>0.023587</td>\n      <td>0.037803</td>\n      <td>0.019531</td>\n      <td>-0.010719</td>\n      <td>0.003869</td>\n      <td>0.010202</td>\n      <td>-0.013388</td>\n      <td>0.025196</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 876 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Get Data Tensor"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(train))\ntrain_data_tensor =  torch.from_numpy(train.astype(np.float32))\ntrain_target_tensor = torch.from_numpy(target.astype(np.float32))","execution_count":298,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"max_val {}, min_val {}\",train_data_tensor.max() , train_data_tensor.min() )\n#Value range b/w -1 to 1 implies that it has been normalized","execution_count":299,"outputs":[{"output_type":"stream","text":"max_val {}, min_val {} tensor(1.) tensor(-0.4424)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_target_tensor)","execution_count":300,"outputs":[{"output_type":"stream","text":"tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sum(sum(train_target_tensor)))","execution_count":301,"outputs":[{"output_type":"stream","text":"tensor(16844.)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"type of train_data_tensor: {}\",type(train_data_tensor) )\ntrain_set = torch.utils.data.TensorDataset(train_data_tensor , train_target_tensor)\nprint(train_set)","execution_count":302,"outputs":[{"output_type":"stream","text":"type of train_data_tensor: {} <class 'torch.Tensor'>\n<torch.utils.data.dataset.TensorDataset object at 0x7f702158c650>\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Get dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 300\ntrain_loader = torch.utils.data.DataLoader(train_set , batch_size = batch_size)\nprint(train_loader)","execution_count":303,"outputs":[{"output_type":"stream","text":"<torch.utils.data.dataloader.DataLoader object at 0x7f70215611d0>\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Now take Instance of Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MultiLabelClassifer(876 , 1024  , 206 )\n#(self , input_feature , hidden_dim , output_dim):\n#model = ModelTWO(876 , 206 , 1024)","execution_count":304,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyser Sample Formed Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = next(iter(train_loader))\nfeature, label = batch","execution_count":305,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(batch[0].shape)\nprint(batch[0][0].shape) #THis is one extracted Feature out of 100","execution_count":306,"outputs":[{"output_type":"stream","text":"torch.Size([300, 876])\ntorch.Size([876])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(feature)","execution_count":307,"outputs":[{"output_type":"stream","text":"tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  9.6001e-03,\n          1.7059e-02,  1.8742e-02],\n        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  ...,  5.6319e-03,\n          2.7579e-02,  3.3451e-02],\n        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ..., -7.6819e-03,\n         -4.9456e-02,  2.4345e-02],\n        ...,\n        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.1164e-03,\n          3.6492e-02,  2.0576e-02],\n        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  8.3413e-04,\n         -2.9741e-02,  5.5212e-03],\n        [ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -5.4815e-02,\n         -2.0204e-02, -3.4210e-02]])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sum(label[0]))\nprint(label[0])   #label for 1st feature data","execution_count":308,"outputs":[{"output_type":"stream","text":"tensor(1.)\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.])\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Now train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport torch.optim as optim\nlearning_rate = [ .01]\n\nfor lr in learning_rate:\n    optimizer = optim.Adam(model.parameters() , lr = lr)\n    criterion = torch.nn.BCELoss()\n\n    for epoch in range(20):\n        model.train()\n        total_loss = 0\n        total_correct = 0\n\n        for batch in train_loader:\n            features , labels  = batch\n            optimizer.zero_grad()\n\n            preds = model(features)\n\n            #print(sum(preds>1))\n            loss = criterion(preds , labels)\n\n\n            loss.backward()\n            optimizer.step() #update weights\n\n            total_loss += loss.data.item()\n            #print(\"total_loss: {}\".format(total_loss))\n            #total_correct  += get_num_correct(preds,labels)\n        print(\" epoch: {} , learning_rate:{} , total_loss: {}\".format(epoch, lr, total_loss))","execution_count":310,"outputs":[{"output_type":"stream","text":" epoch: 0 , learning_rate:0.01 , total_loss: 1230.1783199310303\n epoch: 1 , learning_rate:0.01 , total_loss: 1230.2430696487427\n epoch: 2 , learning_rate:0.01 , total_loss: 1230.959243774414\n epoch: 3 , learning_rate:0.01 , total_loss: 1229.1861820220947\n epoch: 4 , learning_rate:0.01 , total_loss: 1230.7115259170532\n epoch: 5 , learning_rate:0.01 , total_loss: 1229.2173929214478\n epoch: 6 , learning_rate:0.01 , total_loss: 1229.7930040359497\n epoch: 7 , learning_rate:0.01 , total_loss: 1229.8431758880615\n epoch: 8 , learning_rate:0.01 , total_loss: 1229.7263431549072\n epoch: 9 , learning_rate:0.01 , total_loss: 1229.221827507019\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"DONe\")","execution_count":311,"outputs":[{"output_type":"stream","text":"DONe\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}